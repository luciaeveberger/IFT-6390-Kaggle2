{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A50eLCcE8mES"
      },
      "outputs": [],
      "source": [
        "#Cleaned Version\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "IX6EIzmD8n-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/data/train_data.csv', delimiter=',')\n",
        "train_results = pd.read_csv('/content/drive/MyDrive/data/train_results.csv', delimiter=',')\n",
        "\n",
        "X = train_data['text'].copy()\n",
        "y = train_results['target'].copy()\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y.unique())\n",
        "y = le.transform(y) #positive:2, negative:0, neutral:1\n",
        "y[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB9xVcrt8pIk",
        "outputId": "70d3790a-7b06-4ae8-d0b6-aa9ddd2c9a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Drop the two columns \n",
        "#df.drop([\"text_wo_stopfreq\", \"text_wo_stopfreqrare\"], axis=1, inplace=True) \n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "english_stopwords = stopwords.words(\"english\")\n",
        "other= [\"..\", \"...\", \"....\", \"... ...\"]\n",
        "negative_words = ('no', 'not')\n",
        "english_stopwords = [e for e in english_stopwords if e not in negative_words]\n",
        "\n",
        "tweet_tokenizer = TweetTokenizer(\n",
        "    preserve_case=False,\n",
        "    strip_handles=True,\n",
        "    reduce_len=False\n",
        ")\n",
        "\n",
        "tokens = []\n",
        "# for tweet in x_train:\n",
        "# gets rid of URLs\n",
        "X = X.apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "X = X.apply(lambda x: remove_urls(x))\n",
        "X = X.apply(lambda x: stem_words(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvm3Sg4h8-xA",
        "outputId": "cc7c6f89-e000-490d-a413-620c92bbc7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLh-y6wVNZB",
        "outputId": "cf7f5226-233d-4e51-8d1e-74c3c087457f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, tweet in enumerate(X):\n",
        "    #print(stem_wordstweet)\n",
        "    #tweet = stem_words(tweet)\n",
        "    #print(tweet)\n",
        "    # brazilian\n",
        "    # if 'traido' in tweet: \n",
        "    #   continue \n",
        "    # if 'îºî' in tweet: \n",
        "    #   continue\n",
        "    # if 'cap des' in tweet: \n",
        "    #   continue\n",
        "    # if \"àª\" in tweet: \n",
        "    #   continue\n",
        "    \n",
        "    string_encode = tweet.encode(\"ascii\", \"ignore\")\n",
        "    tweet = string_encode.decode()\n",
        "    tweet = tweet.replace(r\"tooooooo\", \"too\")\n",
        "    tweet = tweet.replace(\";)\", \"smile\")\n",
        "    tweet = tweet.replace(\":-D\", \"lovw\")\n",
        "    tweet = tweet.replace(\"=]\", \"love\")\n",
        "    tweet = tweet.replace(\"xxx\", \"kiss\")\n",
        "    tweet = tweet.replace(\"thx\", \"thanks\")\n",
        "    tweet = tweet.replace(\"hhhhhh\", \"\")\n",
        "    tweet = tweet.replace(\"ooooooooooooooooooooo\", \"\")\n",
        "    tweet = tweet.replace(\"f......g\", \"fucking\")\n",
        "    tweet = tweet.replace(\"aaaa\", \"a\")\n",
        "\n",
        "    # removes digits\n",
        "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
        "    token = tweet_tokenizer.tokenize(tweet)\n",
        "    token_clened = [word for word in token if (word not in string.punctuation and word not in other)]\n",
        "    #if i % 200 == 0:\n",
        "    #  print(token_clened)\n",
        "    #token_clened = [word for word in token if (word not in other and word not in string.punctuation)]\n",
        "    #print(token_clened)\n",
        "    tokens.append(token_clened)"
      ],
      "metadata": {
        "id": "RO6XCofgFxw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pad the X Sequences to Size 32 \n",
        "\n",
        "Convert the y_train to categroial "
      ],
      "metadata": {
        "id": "vPrpXrt53azW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the sentences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# fit on the 20000\n",
        "tokenizer = Tokenizer(lower=False)\n",
        "tokenizer.fit_on_texts(tokens)\n",
        "print(len(tokenizer.word_counts))\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y, 3)\n",
        "print(len(tokens))\n",
        "train_text_vec = tokenizer.texts_to_sequences(tokens)\n",
        "train_text_vec = pad_sequences(train_text_vec, maxlen=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ChZ3OxzO0e3",
        "outputId": "2b4d8815-3d4b-4e18-f588-a67c7f1e0358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9IBjnb5oTUNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_text_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akEuo0JOVVO7",
        "outputId": "4dc88037-caec-4113-c54d-1a3c9a0794ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1040323"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM Variations\n",
        "\n",
        "I built several different biLSTM variations."
      ],
      "metadata": {
        "id": "809WRk4NGt1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we might want to change these\n",
        "MAX_SEQ_LEN = 32 #this is based on a quick analysis of the len of sequences train['text'].apply(lambda x : len(x.split(' '))).quantile(0.95)\n",
        "DEFAULT_BATCH_SIZE = 512\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import f1_score, classification_report, log_loss\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Flatten\n",
        "from keras.layers import Dropout, Conv1D, GlobalMaxPool1D, GRU, GlobalAvgPool1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import (Embedding,\n",
        "                                     LSTM,\n",
        "                                     Dense,\n",
        "                                     Dropout,\n",
        "                                     GlobalMaxPool1D,\n",
        "                                     BatchNormalization)\n",
        "def train(model, \n",
        "          X_train, y_train, X_test, y_test, \n",
        "          checkpoint_path='model.hdf5', \n",
        "          epochs = 25, \n",
        "          batch_size = DEFAULT_BATCH_SIZE, \n",
        "          class_weights = None, \n",
        "          fit_verbose=2,\n",
        "          print_summary = True\n",
        "         ):\n",
        "    m = model()\n",
        "    if print_summary:\n",
        "        print(m.summary())\n",
        "    m.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        #this is bad practice using test data for validation, in a real case would use a seperate validation set\n",
        "        validation_data=(X_test, y_test),  \n",
        "        epochs=epochs, \n",
        "        batch_size=batch_size,\n",
        "        class_weight=class_weights,\n",
        "         #saves the most accurate model, usually you would save the one with the lowest loss\n",
        "        callbacks= [\n",
        "            ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=False),\n",
        "            EarlyStopping(patience = 2)\n",
        "        ],\n",
        "        verbose=1\n",
        "    ) \n",
        "    print(\"\\n\\n****************************\\n\\n\")\n",
        "    print('Loading Best Model...')s\n",
        "    return m #returns best performing model\n",
        "\n",
        "\n",
        "def model_1d():\n",
        "  VECTOR_FEATURES = 32\n",
        "  lstm_model = Sequential()\n",
        "  # could be smaller\n",
        "  lstm_model.add(Embedding(len((tokenizer.word_counts))+1,\n",
        "                      VECTOR_FEATURES,\n",
        "                      input_length= MAX_SEQ_LEN))\n",
        "  lstm_model.add(LSTM(280, return_sequences = True))\n",
        "  lstm_model.add(GlobalMaxPool1D())\n",
        "  lstm_model.add(BatchNormalization())\n",
        "  lstm_model.add(Dropout(0.5))\n",
        "  lstm_model.add(Dense(10, activation=\"relu\"))\n",
        "  lstm_model.add(Dropout(0.25))\n",
        "  lstm_model.add(Dense(3, activation = \"sigmoid\"))\n",
        "  lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return lstm_model\n",
        "\n",
        "\n",
        "def model_1c():\n",
        "    \"\"\"\n",
        "    Adding dropout to reduce overfitting using a bidiretional LSTM\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim = (len((tokenizer.word_counts))+1), output_dim = 108, input_length = 32))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(Bidirectional(LSTM(108, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "    model.add(Conv1D(64, 4))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(Dense(108, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(3, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "WhkJa15CFUEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi LSTM, Larger Model"
      ],
      "metadata": {
        "id": "UHI85h_KTYl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLKJv5nyTY59",
        "outputId": "dcd38d87-6913-47d9-aa03-4aa86a3691c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1040323, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7--mhHATaUu",
        "outputId": "31999b3c-d026-49a4-f6cc-02dd72c37ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1040323, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_text_vec, y_train, train_size = 0.7, random_state=42)"
      ],
      "metadata": {
        "id": "YkHMigL2k-DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(tokenizer.word_counts))\n",
        "model = train(model_1d, \n",
        "           X_train,\n",
        "           y_train,\n",
        "           X_val,\n",
        "           y_val,\n",
        "           checkpoint_path='/content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1c.h5',\n",
        "           print_summary = True\n",
        "          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcXEmEcFPgbW",
        "outputId": "2e8684c1-848c-4937-a700-ee4640357a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254585\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 32)            8146752   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32, 280)           350560    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 280)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 280)              1120      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 280)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                2810      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,501,275\n",
            "Trainable params: 8,500,715\n",
            "Non-trainable params: 560\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7796\n",
            "Epoch 1: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1c.h5\n",
            "1423/1423 [==============================] - 45s 26ms/step - loss: 0.4846 - accuracy: 0.7796 - val_loss: 0.4176 - val_accuracy: 0.8079\n",
            "Epoch 2/25\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8278\n",
            "Epoch 2: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1c.h5\n",
            "1423/1423 [==============================] - 38s 27ms/step - loss: 0.3972 - accuracy: 0.8278 - val_loss: 0.4143 - val_accuracy: 0.8107\n",
            "Epoch 3/25\n",
            "1421/1423 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.8531\n",
            "Epoch 3: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1c.h5\n",
            "1423/1423 [==============================] - 39s 27ms/step - loss: 0.3485 - accuracy: 0.8531 - val_loss: 0.4352 - val_accuracy: 0.8088\n",
            "Epoch 4/25\n",
            "1422/1423 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8719\n",
            "Epoch 4: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1c.h5\n",
            "1423/1423 [==============================] - 39s 27ms/step - loss: 0.3075 - accuracy: 0.8719 - val_loss: 0.4635 - val_accuracy: 0.8067\n",
            "\n",
            "\n",
            "****************************\n",
            "\n",
            "\n",
            "Loading Best Model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model (81.2%)\n"
      ],
      "metadata": {
        "id": "x-tUQN67f8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1c = train(model_1c, \n",
        "           X_train,\n",
        "           y_train,\n",
        "           X_val,\n",
        "           y_val,\n",
        "           epochs=2,\n",
        "           checkpoint_path='/content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5',\n",
        "           print_summary = True\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LAEUNXTQ5L",
        "outputId": "f2a34485-4f1a-4ab8-cec1-2f0a11d1c884"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 108)           27495288  \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 32, 108)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32, 216)          187488    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 29, 64)            55360     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 108)               7020      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 108)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 327       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,745,483\n",
            "Trainable params: 27,745,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.7891\n",
            "Epoch 1: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5\n",
            "1423/1423 [==============================] - 473s 323ms/step - loss: 0.4483 - accuracy: 0.7891 - val_loss: 0.4057 - val_accuracy: 0.8136\n",
            "Epoch 2/2\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8344\n",
            "Epoch 2: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5\n",
            "1423/1423 [==============================] - 450s 316ms/step - loss: 0.3738 - accuracy: 0.8344 - val_loss: 0.3973 - val_accuracy: 0.8200\n",
            "\n",
            "\n",
            "****************************\n",
            "\n",
            "\n",
            "Loading Best Model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Test Dataset"
      ],
      "metadata": {
        "id": "BiIvY1LwG4wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/drive/MyDrive/data/test_data.csv\")\n",
        "X_test = test_data['text'].copy()\n",
        "\n",
        "\n",
        "\n",
        "tokens_test = []\n",
        "X_test = X_test.apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "X_test = X_test.apply(lambda x: remove_urls(x))\n",
        "for i, tweet in enumerate(X_test):\n",
        "\n",
        "    string_encode = tweet.encode(\"ascii\", \"ignore\")\n",
        "    tweet = string_encode.decode()\n",
        "    tweet = tweet.replace(r\"tooooooo\", \"too\")\n",
        "    tweet = tweet.replace(\";)\", \"smile\")\n",
        "    tweet = tweet.replace(\":-D\", \"lovw\")\n",
        "    tweet = tweet.replace(\"=]\", \"love\")\n",
        "    tweet = tweet.replace(\"xxx\", \"kiss\")\n",
        "    tweet = tweet.replace(\"thx\", \"thanks\")\n",
        "    tweet = tweet.replace(\"hhhhhh\", \"\")\n",
        "    tweet = tweet.replace(\"ooooooooooooooooooooo\", \"\")\n",
        "    tweet = tweet.replace(\"f......g\", \"fucking\")\n",
        "    tweet = tweet.replace(\"aaaa\", \"a\")\n",
        "    tweet = tweet.replace(\"iii\", \"\")\n",
        "    tweet = tweet.replace(\"uhhhhhmmm\", \"um\")\n",
        "    tweet = tweet.replace(\"hahahahaah\", \"haha\")\n",
        "    tweet = tweet.replace(\"hahaha\", \"haha\")\n",
        "    tweet = tweet.replace(\"plllleeeaassseeeee\", \"please\")\n",
        "    tweet = tweet.replace(\"cccccrrrrrrrrrrrrryyyyyyyyy\", \"cry\")\n",
        "    tweet = tweet.replace(\"ssssssssss\", \"s\")\n",
        "    tweet = tweet.replace(\"grrrrrrr\", \"gr\")\n",
        "    tweet = tweet.replace(\":]\", \"happy\")\n",
        "    tweet = tweet.replace(\"ll\", \"\")\n",
        "    tweet = tweet.replace(\"luvvv\", \"love\")\n",
        "    token = tweet_tokenizer.tokenize(tweet)\n",
        "    \n",
        "\n",
        "    token_clened = [word for word in token if (word not in string.punctuation and word not in other)]\n",
        "    #print(token_clened)\n",
        "    #if i % 200 == 0:\n",
        "    #  print(token_clened)\n",
        "    #token_clened = [word for word in token if (word not in other and word not in string.punctuation)]\n",
        "    #print(token_clened)\n",
        "    tokens_test.append(token_clened)"
      ],
      "metadata": {
        "id": "_ZpbMvttdWxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepping evaluation data\n",
        "import numpy as np\n",
        "\n",
        "test_text_vec = tokenizer.texts_to_sequences(tokens_test)\n",
        "test_text_vec = pad_sequences(test_text_vec, maxlen=32)\n",
        "\n",
        "model_bi_lstm_predictions = model_1c.predict(test_text_vec)\n",
        "predictions = np.argmax(model_bi_lstm_predictions, axis=1)\n",
        "\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/no_stop_words_processed_with_bltm_removal_of_other_parts.csv\",\"a\")\n",
        "file.write(\"id,target\\n\")\n",
        "count = 0 \n",
        "for prediction in predictions:\n",
        "    output = str(int(prediction))\n",
        "    file.write(str(count) + \",\" + output + \"\\n\")\n",
        "    count = count + 1 \n",
        "file.close()"
      ],
      "metadata": {
        "id": "8NQq8oyKWSdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a62f90-e756-4a50-86bd-94ace1f3d33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17506/17506 [==============================] - 332s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conformer RNNT & Larger BLSTM"
      ],
      "metadata": {
        "id": "ZX2NvICwHBMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "MAX_SEQ_LEN=32\n",
        "inputs = layers.Input(shape=(MAX_SEQ_LEN,))\n",
        "# to do: make this smaller?\n",
        "embedding_layer = TokenAndPositionEmbedding(MAX_SEQ_LEN, len(tokenizer.word_counts)+1, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(108, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(3, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "# use much larger batch sizes \n",
        "# monitor only the eval set for the losses + stop after 5 {early stopping criteron}\n",
        "# batch size, epcohs+ etc\n",
        "#  X_train,\n",
        "          #  y_train,\n",
        "          #  X_val,\n",
        "          #  y_val,\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), \n",
        "    callbacks= [\n",
        "            ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/DataChallenge2/transformer.md\", \n",
        "                            monitor='val_loss', \n",
        "                            verbose=1,\n",
        "                            mode=\"auto\",\n",
        "                            save_best_only=True),\n",
        "            EarlyStopping(patience = 2)\n",
        "        ],\n",
        "        verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "p4dftv3spo2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_1c_larger():\n",
        "    \"\"\"\n",
        "    Adding dropout to reduce overfitting using a bidiretional LSTM\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim = (len((tokenizer.word_counts))+1), output_dim = 216, input_length = 32))\n",
        "    model.add(SpatialDropout1D(0.3))\n",
        "    model.add(Bidirectional(LSTM(216, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
        "    model.add(Conv1D(64, 4))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(Dense(216, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(3, activation='sigmoid'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BHy8or0Qxf7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1c_larger = train(model_1c_larger, \n",
        "           X_train,\n",
        "           y_train,\n",
        "           X_val,\n",
        "           y_val,\n",
        "           epochs=2,\n",
        "           checkpoint_path='/content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5',\n",
        "           print_summary = True\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTXN_Gwu2eSz",
        "outputId": "06da0a5f-b0f4-4437-b100-c6e05d973cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 32, 216)           54990576  \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 32, 216)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 32, 432)          748224    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 29, 64)            110656    \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 216)               14040     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 216)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 651       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,864,147\n",
            "Trainable params: 55,864,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7937\n",
            "Epoch 1: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5\n",
            "1423/1423 [==============================] - 560s 390ms/step - loss: 0.4386 - accuracy: 0.7937 - val_loss: 0.4022 - val_accuracy: 0.8174\n",
            "Epoch 2/2\n",
            "1423/1423 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8395\n",
            "Epoch 2: saving model to /content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5\n",
            "1423/1423 [==============================] - 493s 347ms/step - loss: 0.3631 - accuracy: 0.8395 - val_loss: 0.3978 - val_accuracy: 0.8209\n",
            "\n",
            "\n",
            "****************************\n",
            "\n",
            "\n",
            "Loading Best Model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses stemming + removes punctution"
      ],
      "metadata": {
        "id": "BGkqF4og2ik7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data['text'].copy()\n",
        "nltk.download('stopwords')\n",
        "english_stopwords = stopwords.words(\"english\")\n",
        "other= [\"..\", \"...\", \"....\", \"... ...\"]\n",
        "negative_words = ('no', 'not')\n",
        "english_stopwords = [e for e in english_stopwords if e not in negative_words]\n",
        "\n",
        "tweet_tokenizer = TweetTokenizer(\n",
        "    preserve_case=False,\n",
        "    strip_handles=True,\n",
        "    reduce_len=False\n",
        ")\n",
        "\n",
        "tokens = []\n",
        "# for tweet in x_train:\n",
        "# gets rid of URLs\n",
        "X = X.apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "X = X.apply(lambda x: remove_urls(x))\n",
        "X = X.apply(lambda x: stem_words(x))\n",
        "\n",
        "\n",
        "\n",
        "for i, tweet in enumerate(X):\n",
        "    \n",
        "    string_encode = tweet.encode(\"ascii\", \"ignore\")\n",
        "    tweet = string_encode.decode()\n",
        "    tweet = tweet.replace(r\"tooooooo\", \"too\")\n",
        "    tweet = tweet.replace(\";)\", \"smile\")\n",
        "    tweet = tweet.replace(\":-D\", \"lovw\")\n",
        "    tweet = tweet.replace(\"=]\", \"love\")\n",
        "    tweet = tweet.replace(\"xxx\", \"kiss\")\n",
        "    tweet = tweet.replace(\"thx\", \"thanks\")\n",
        "    tweet = tweet.replace(\"hhhhhh\", \"\")\n",
        "    tweet = tweet.replace(\"ooooooooooooooooooooo\", \"\")\n",
        "    tweet = tweet.replace(\"f......g\", \"fucking\")\n",
        "    tweet = tweet.replace(\"aaaa\", \"a\")\n",
        "    # stems the tweet \n",
        "    tweet = stem_words(tweet)\n",
        "\n",
        "\n",
        "    # removes digits\n",
        "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
        "    token = tweet_tokenizer.tokenize(tweet)\n",
        "    token_clened = [word for word in token if (word not in string.punctuation and word not in other)]\n",
        "    if i % 1000 == 0:\n",
        "      print(token_clened)\n",
        "    #token_clened = [word for word in token if (word not in other and word not in string.punctuation)]\n",
        "    #print(token_clened)\n",
        "    tokens.append(token_clened)"
      ],
      "metadata": {
        "id": "g70aDoE53cmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the sentences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# fit on the 20000\n",
        "tokenizer = Tokenizer(lower=False)\n",
        "tokenizer.fit_on_texts(tokens)\n",
        "print(len(tokenizer.word_counts))\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y, 3)\n",
        "print(len(tokens))\n",
        "train_text_vec = tokenizer.texts_to_sequences(tokens)\n",
        "train_text_vec = pad_sequences(train_text_vec, maxlen=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0N_Iqmc3oLB",
        "outputId": "44227201-7e3c-4eee-a6a4-a34c26aa5386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224484\n",
            "1040323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_text_vec, y_train, train_size = 0.7, random_state=42)"
      ],
      "metadata": {
        "id": "kfoKJr3A9drH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFcmWJmk9rZu",
        "outputId": "afbdb96e-e54a-4f16-e654-611793d055b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(728226, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#X_train, X_val, y_train, y_val = train_test_split(train_text_vec, y_train, train_size = 0.7, random_state=42)\n",
        "model_1c_larger = train(model_1c_larger, \n",
        "           X_train,\n",
        "           y_train,\n",
        "           X_val,\n",
        "           y_val,\n",
        "           epochs=2,\n",
        "           checkpoint_path='/content/drive/MyDrive/Colab Notebooks/DataChallenge2/_model_1d.h5',\n",
        "           print_summary = True\n",
        "          )"
      ],
      "metadata": {
        "id": "mNRxAk8N8FZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepping evaluation data\n",
        "import numpy as np\n",
        "\n",
        "test_text_vec = tokenizer.texts_to_sequences(tokens_test)\n",
        "test_text_vec = pad_sequences(test_text_vec, maxlen=32)\n",
        "\n",
        "model_bi_lstm_predictions = model_1c_larger.predict(test_text_vec)\n",
        "predictions = np.argmax(model_bi_lstm_predictions, axis=1)\n",
        "\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/second_try_no_stop_words_processed_with_bltm_removal_of_other_parts.csv\",\"a\")\n",
        "file.write(\"id,target\\n\")\n",
        "count = 0 \n",
        "for prediction in predictions:\n",
        "    output = str(int(prediction))\n",
        "    file.write(str(count) + \",\" + output + \"\\n\")\n",
        "    count = count + 1 \n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u422Oeyt9K6B",
        "outputId": "fb28e349-b85b-41af-aa1f-085931612b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17506/17506 [==============================] - 332s 19ms/step\n"
          ]
        }
      ]
    }
  ]
}
